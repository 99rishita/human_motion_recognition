{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as scio\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from micro_doppler import read_data, data_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## positive and neg samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "953\n"
     ]
    }
   ],
   "source": [
    "data_pos = read_data('data/pos')\n",
    "data_neg = read_data('data/neg')\n",
    "training_data = []\n",
    "label_list = []\n",
    "tmp_1, tmp_2 = data_transform(data_pos, 1)\n",
    "training_data = training_data + tmp_1\n",
    "label_list = label_list + tmp_2\n",
    "tmp_1, tmp_2 = data_transform(data_neg, 0)\n",
    "training_data_r = training_data + tmp_1\n",
    "label_list = label_list + tmp_2 \n",
    "print(len(label_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transform\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoches = 2000\n",
    "num_classes = 2\n",
    "batch_size = 25\n",
    "learning_rate = 0.0001\n",
    "model = ConvNet()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = training_data_r\n",
    "training_data = [[training_data[i].reshape(1,128,20), label_list[i]] for i in range(len(training_data))]\n",
    "train, test = train_test_split(training_data, test_size=0.2, random_state=42)\n",
    "training_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "testing_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "loss is:  0.6857504844665527\n",
      "loss is:  0.6802947521209717\n",
      "loss is:  0.6963122487068176\n",
      "loss is:  0.6672723293304443\n",
      "loss is:  0.6501767039299011\n",
      "loss is:  0.6610069274902344\n",
      "loss is:  0.6408617496490479\n",
      "loss is:  0.6493569016456604\n",
      "loss is:  0.6170657277107239\n",
      "loss is:  0.650794506072998\n",
      "loss is:  0.6464492082595825\n",
      "loss is:  0.6477820873260498\n",
      "loss is:  0.6544573903083801\n",
      "loss is:  0.5959327220916748\n",
      "loss is:  0.6058251857757568\n",
      "loss is:  0.604397714138031\n",
      "loss is:  0.5829238295555115\n",
      "loss is:  0.6303224563598633\n",
      "loss is:  0.5945602655410767\n",
      "loss is:  0.6261314153671265\n",
      "loss is:  0.605935275554657\n",
      "loss is:  0.6258361339569092\n",
      "loss is:  0.5810220837593079\n",
      "loss is:  0.5759877562522888\n",
      "loss is:  0.5900402069091797\n",
      "loss is:  0.6305189728736877\n",
      "loss is:  0.5957614779472351\n",
      "loss is:  0.6163377165794373\n",
      "loss is:  0.5596966743469238\n",
      "loss is:  0.5693390965461731\n",
      "loss is:  0.6304250955581665\n",
      "loss is:  0.6667951345443726\n",
      "loss is:  0.5684438347816467\n",
      "loss is:  0.5828407406806946\n",
      "loss is:  0.5476052761077881\n",
      "loss is:  0.6426843404769897\n",
      "loss is:  0.5663143992424011\n",
      "loss is:  0.5944250822067261\n",
      "loss is:  0.48023131489753723\n",
      "loss is:  0.5777263045310974\n",
      "loss is:  0.614311933517456\n",
      "loss is:  0.638996422290802\n",
      "loss is:  0.5604153275489807\n",
      "loss is:  0.5431181192398071\n",
      "loss is:  0.5352978110313416\n",
      "loss is:  0.5425054430961609\n",
      "loss is:  0.4861409366130829\n",
      "loss is:  0.5643281936645508\n",
      "loss is:  0.5334386825561523\n",
      "loss is:  0.622307538986206\n",
      "loss is:  0.5655762553215027\n",
      "loss is:  0.516017735004425\n",
      "loss is:  0.48859959840774536\n",
      "loss is:  0.5726617574691772\n",
      "loss is:  0.5410464406013489\n",
      "loss is:  0.5424676537513733\n",
      "loss is:  0.5446099042892456\n",
      "loss is:  0.5592930912971497\n",
      "loss is:  0.5232480764389038\n",
      "loss is:  0.5809751152992249\n",
      "loss is:  0.5342530608177185\n",
      "loss is:  0.5248047709465027\n",
      "loss is:  0.5592533349990845\n",
      "loss is:  0.48379436135292053\n",
      "loss is:  0.5112806558609009\n",
      "loss is:  0.533789873123169\n",
      "loss is:  0.4894635081291199\n",
      "loss is:  0.5012063384056091\n",
      "loss is:  0.495186448097229\n",
      "loss is:  0.48909270763397217\n",
      "loss is:  0.5054405927658081\n",
      "loss is:  0.502840518951416\n",
      "loss is:  0.539053738117218\n",
      "loss is:  0.6007910370826721\n",
      "loss is:  0.5671079754829407\n",
      "loss is:  0.5125619769096375\n",
      "loss is:  0.46889838576316833\n",
      "loss is:  0.5709420442581177\n",
      "loss is:  0.5545917749404907\n",
      "loss is:  0.5056370496749878\n",
      "loss is:  0.5245416760444641\n",
      "loss is:  0.5749478936195374\n",
      "loss is:  0.4904789328575134\n",
      "loss is:  0.5023074746131897\n",
      "loss is:  0.4694536328315735\n",
      "loss is:  0.5639882683753967\n",
      "loss is:  0.5614041090011597\n",
      "loss is:  0.5806329846382141\n",
      "loss is:  0.5635474324226379\n",
      "loss is:  0.562016487121582\n",
      "loss is:  0.6221129894256592\n",
      "loss is:  0.4727272391319275\n",
      "loss is:  0.5357386469841003\n",
      "loss is:  0.526753842830658\n",
      "loss is:  0.5122734308242798\n",
      "loss is:  0.4412977695465088\n",
      "loss is:  0.4684709906578064\n",
      "loss is:  0.5581004619598389\n",
      "loss is:  0.45902329683303833\n",
      "loss is:  0.48333752155303955\n",
      "loss is:  0.5139292478561401\n",
      "loss is:  0.6136134266853333\n",
      "loss is:  0.49116280674934387\n",
      "loss is:  0.6331893801689148\n",
      "loss is:  0.49868011474609375\n",
      "loss is:  0.5364648103713989\n",
      "loss is:  0.49391382932662964\n",
      "loss is:  0.6034300923347473\n",
      "loss is:  0.48882147669792175\n",
      "loss is:  0.552472710609436\n",
      "loss is:  0.5254416465759277\n",
      "loss is:  0.45455771684646606\n",
      "loss is:  0.418623685836792\n",
      "loss is:  0.5078636407852173\n",
      "loss is:  0.46274101734161377\n",
      "loss is:  0.6251024007797241\n",
      "loss is:  0.45544204115867615\n",
      "loss is:  0.4513092041015625\n",
      "loss is:  0.5559532642364502\n",
      "loss is:  0.5000784993171692\n",
      "loss is:  0.5382011532783508\n",
      "loss is:  0.42921364307403564\n",
      "loss is:  0.5169259905815125\n",
      "loss is:  0.5598281025886536\n",
      "loss is:  0.5389206409454346\n",
      "loss is:  0.5230962634086609\n",
      "loss is:  0.5663020610809326\n",
      "loss is:  0.5028484463691711\n",
      "loss is:  0.5604485273361206\n",
      "loss is:  0.5291425585746765\n",
      "loss is:  0.507519543170929\n",
      "loss is:  0.4549928605556488\n",
      "loss is:  0.4861850440502167\n",
      "loss is:  0.5262748003005981\n",
      "loss is:  0.4736926257610321\n",
      "loss is:  0.5486118793487549\n",
      "loss is:  0.4787953495979309\n",
      "loss is:  0.5902369022369385\n",
      "loss is:  0.4070221185684204\n",
      "loss is:  0.4388786256313324\n",
      "loss is:  0.4999738931655884\n",
      "loss is:  0.4997427463531494\n",
      "loss is:  0.44198817014694214\n",
      "loss is:  0.526068925857544\n",
      "loss is:  0.5558091402053833\n",
      "loss is:  0.528423547744751\n",
      "loss is:  0.5146855711936951\n",
      "loss is:  0.4324701726436615\n",
      "loss is:  0.43474656343460083\n",
      "loss is:  0.5001227855682373\n",
      "loss is:  0.4402274191379547\n",
      "loss is:  0.47547125816345215\n",
      "loss is:  0.631580114364624\n",
      "loss is:  0.5425757765769958\n",
      "loss is:  0.4668256342411041\n",
      "loss is:  0.38127681612968445\n",
      "loss is:  0.49774283170700073\n",
      "loss is:  0.44717198610305786\n",
      "loss is:  0.41889622807502747\n",
      "loss is:  0.4326006770133972\n",
      "loss is:  0.48626208305358887\n",
      "loss is:  0.5451480746269226\n",
      "loss is:  0.43952861428260803\n",
      "loss is:  0.45843246579170227\n",
      "loss is:  0.4765702188014984\n",
      "loss is:  0.5476906895637512\n",
      "loss is:  0.45977362990379333\n",
      "loss is:  0.5435760021209717\n",
      "loss is:  0.46367302536964417\n",
      "loss is:  0.5009527802467346\n",
      "loss is:  0.4544369876384735\n",
      "loss is:  0.4072444438934326\n",
      "loss is:  0.5599144101142883\n",
      "loss is:  0.5587112307548523\n",
      "loss is:  0.4602600038051605\n",
      "loss is:  0.4972391426563263\n",
      "loss is:  0.46089789271354675\n",
      "loss is:  0.5714337825775146\n",
      "loss is:  0.598842978477478\n",
      "loss is:  0.5252751111984253\n",
      "loss is:  0.6027860641479492\n",
      "loss is:  0.4420510530471802\n",
      "loss is:  0.4836634695529938\n",
      "loss is:  0.6066505312919617\n",
      "loss is:  0.6109710931777954\n",
      "loss is:  0.5550221800804138\n",
      "loss is:  0.5418638586997986\n",
      "loss is:  0.4823337495326996\n",
      "loss is:  0.45301133394241333\n",
      "loss is:  0.5649142265319824\n",
      "loss is:  0.689729630947113\n",
      "loss is:  0.44143053889274597\n",
      "loss is:  0.4523998498916626\n",
      "loss is:  0.42990025877952576\n",
      "loss is:  0.4315751791000366\n",
      "loss is:  0.49633729457855225\n",
      "loss is:  0.5064871311187744\n",
      "loss is:  0.4571215808391571\n",
      "loss is:  0.41810810565948486\n",
      "loss is:  0.451121062040329\n",
      "loss is:  0.4729059934616089\n",
      "loss is:  0.5236043334007263\n",
      "loss is:  0.5306503176689148\n",
      "loss is:  0.5680940747261047\n",
      "loss is:  0.5197094082832336\n",
      "loss is:  0.496659517288208\n",
      "loss is:  0.5293645262718201\n",
      "loss is:  0.44747355580329895\n",
      "loss is:  0.5354476571083069\n",
      "loss is:  0.46231311559677124\n",
      "loss is:  0.4042130410671234\n",
      "loss is:  0.4716233015060425\n",
      "loss is:  0.4094546437263489\n",
      "loss is:  0.480621874332428\n",
      "loss is:  0.5234764814376831\n",
      "loss is:  0.49196088314056396\n",
      "loss is:  0.5782522559165955\n",
      "loss is:  0.49245694279670715\n",
      "loss is:  0.48571521043777466\n",
      "loss is:  0.4441262185573578\n",
      "loss is:  0.4385920763015747\n",
      "loss is:  0.4879668951034546\n",
      "loss is:  0.4899482727050781\n",
      "loss is:  0.5155906081199646\n",
      "loss is:  0.5587570071220398\n",
      "loss is:  0.4549255073070526\n",
      "loss is:  0.44520893692970276\n",
      "loss is:  0.5113013982772827\n",
      "loss is:  0.4818555414676666\n",
      "loss is:  0.407135009765625\n",
      "loss is:  0.46238502860069275\n",
      "loss is:  0.4526715576648712\n",
      "loss is:  0.4916800558567047\n",
      "loss is:  0.45760661363601685\n",
      "loss is:  0.5811874270439148\n",
      "loss is:  0.4524112641811371\n",
      "loss is:  0.4411523938179016\n",
      "loss is:  0.4654459059238434\n",
      "loss is:  0.4822680354118347\n",
      "loss is:  0.5637409687042236\n",
      "loss is:  0.4260180592536926\n",
      "loss is:  0.5470173358917236\n",
      "loss is:  0.4894709289073944\n",
      "loss is:  0.4695793390274048\n",
      "loss is:  0.4695018529891968\n",
      "loss is:  0.5087131261825562\n",
      "loss is:  0.4120442867279053\n",
      "loss is:  0.43609413504600525\n",
      "loss is:  0.38410454988479614\n",
      "loss is:  0.5100768804550171\n",
      "loss is:  0.4641598165035248\n",
      "loss is:  0.45240119099617004\n",
      "loss is:  0.5072500705718994\n",
      "loss is:  0.5068863034248352\n",
      "loss is:  0.4677485525608063\n",
      "loss is:  0.4469078481197357\n",
      "loss is:  0.4794484078884125\n",
      "loss is:  0.5276256203651428\n",
      "loss is:  0.5263071656227112\n",
      "loss is:  0.43966683745384216\n",
      "loss is:  0.45354294776916504\n",
      "loss is:  0.543662428855896\n",
      "loss is:  0.5065199732780457\n",
      "loss is:  0.399959534406662\n",
      "loss is:  0.47855931520462036\n",
      "loss is:  0.5549001097679138\n",
      "loss is:  0.4743991196155548\n",
      "loss is:  0.3915523886680603\n",
      "loss is:  0.6111837029457092\n",
      "loss is:  0.4620009660720825\n",
      "loss is:  0.4806232154369354\n",
      "loss is:  0.6272793412208557\n",
      "loss is:  0.5728535056114197\n",
      "loss is:  0.43633267283439636\n",
      "loss is:  0.41350415349006653\n",
      "loss is:  0.5038321018218994\n",
      "loss is:  0.5419636964797974\n",
      "loss is:  0.6053686738014221\n",
      "loss is:  0.5721550583839417\n",
      "loss is:  0.6052491664886475\n",
      "loss is:  0.4944506585597992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is:  0.5193058252334595\n",
      "loss is:  0.4432530999183655\n",
      "loss is:  0.4740678668022156\n",
      "loss is:  0.5193474292755127\n",
      "loss is:  0.471665620803833\n",
      "loss is:  0.4556586444377899\n",
      "loss is:  0.4354676902294159\n",
      "loss is:  0.5092547535896301\n",
      "loss is:  0.495432049036026\n",
      "loss is:  0.46483680605888367\n",
      "loss is:  0.5173741579055786\n",
      "loss is:  0.44501402974128723\n",
      "loss is:  0.5279849767684937\n",
      "loss is:  0.4445788860321045\n",
      "loss is:  0.4596538543701172\n",
      "loss is:  0.4514569938182831\n",
      "loss is:  0.4677121639251709\n",
      "loss is:  0.5738822817802429\n",
      "loss is:  0.4291684329509735\n",
      "loss is:  0.3858691155910492\n",
      "loss is:  0.6049907207489014\n",
      "loss is:  0.44877979159355164\n",
      "loss is:  0.39939945936203003\n",
      "loss is:  0.47664883732795715\n",
      "loss is:  0.4209883511066437\n",
      "loss is:  0.483623206615448\n",
      "loss is:  0.5189036726951599\n",
      "loss is:  0.4505387842655182\n",
      "loss is:  0.48276758193969727\n",
      "loss is:  0.4824256896972656\n",
      "loss is:  0.3477429151535034\n",
      "loss is:  0.4471493065357208\n",
      "loss is:  0.6129866242408752\n",
      "loss is:  0.46970367431640625\n",
      "loss is:  0.4067012667655945\n",
      "loss is:  0.4652790129184723\n",
      "loss is:  0.46784400939941406\n",
      "loss is:  0.4725431501865387\n",
      "loss is:  0.46128326654434204\n",
      "loss is:  0.5922940969467163\n",
      "loss is:  0.4305611550807953\n",
      "loss is:  0.4835691750049591\n",
      "loss is:  0.5168257355690002\n",
      "loss is:  0.417314350605011\n",
      "loss is:  0.476755291223526\n",
      "loss is:  0.3769211173057556\n",
      "loss is:  0.4634866714477539\n",
      "loss is:  0.4480075538158417\n",
      "loss is:  0.5017235279083252\n",
      "loss is:  0.5134403109550476\n",
      "loss is:  0.4165251553058624\n",
      "loss is:  0.5417410135269165\n",
      "loss is:  0.49410155415534973\n",
      "loss is:  0.41991856694221497\n",
      "loss is:  0.4652760326862335\n",
      "loss is:  0.4506472647190094\n",
      "loss is:  0.4714410901069641\n",
      "loss is:  0.43774187564849854\n",
      "loss is:  0.46221908926963806\n",
      "loss is:  0.39491069316864014\n",
      "loss is:  0.41555559635162354\n",
      "loss is:  0.41863566637039185\n",
      "loss is:  0.4445698857307434\n",
      "loss is:  0.4490155279636383\n",
      "loss is:  0.4768017530441284\n",
      "loss is:  0.5136244297027588\n",
      "loss is:  0.5076389908790588\n",
      "loss is:  0.40757331252098083\n",
      "loss is:  0.3644232153892517\n",
      "loss is:  0.4480104446411133\n",
      "loss is:  0.5169627666473389\n",
      "loss is:  0.5664270520210266\n",
      "loss is:  0.5238520503044128\n",
      "loss is:  0.4011719524860382\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "total_step = len(training_loader)\n",
    "print(total_step)\n",
    "for epoch in range(num_epoches):\n",
    "    for i, (images, labels) in enumerate(training_loader):\n",
    "#         images = images.to(device)\n",
    "#         labels = labels.to(device)\n",
    "        images = images.float()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)    \n",
    "        print('loss is: ', loss.item())\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epoches, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the test images: 81.15183246073299 %\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in testing_loader:\n",
    "#         images = images.to(device)\n",
    "#         labels = labels.to(device)\n",
    "        images = images.float()\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    print('Test Accuracy of the model on the test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Device configuration\n",
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout2d(0.05))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout2d(0.05))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout2d(0.05))      \n",
    "        \n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Linear(4096, 128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout2d(0.05)            \n",
    "        )\n",
    "        self.outputlayer = nn.Linear(128, num_classes)\n",
    "       \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.layer4(out)\n",
    "        out = self.outputlayer(out)\n",
    "        out = F.softmax(out, dim=1)\n",
    "        return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
